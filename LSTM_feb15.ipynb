{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09yEwvYJFyW_"
      },
      "source": [
        "# **Data Prep**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "drk9cTygIj1-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/payalpatel/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Import libraries here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Input\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import MeanAbsolutePercentageError\n",
        "from statsmodels.tsa.arima.model import ARIMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p2fueWkrFJ7M"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('/Users/payalpatel/Downloads/HomeC.csv', low_memory=False)\n",
        "\n",
        "# Preprocessing\n",
        "df['cloudCover'] = pd.to_numeric(df['cloudCover'], errors='coerce')\n",
        "df['time'] = pd.to_datetime(df['time'], format='%H:%M:%S', errors='coerce').dt.time\n",
        "df.loc[:, 'icon'] = df['icon'].fillna('Unknown')\n",
        "df.loc[:, 'summary'] = df['summary'].fillna('Unknown')\n",
        "df = pd.get_dummies(df, columns=['icon', 'summary'])\n",
        "\n",
        "# Create variables for the columns that are relevant from the dataset\n",
        "target_variable = 'House overall [kW]'\n",
        "weather_variables = ['temperature', 'humidity', 'visibility', 'windSpeed', 'cloudCover',\n",
        "            'dewPoint', 'precipIntensity', 'precipProbability']\n",
        "\n",
        "# Prepare dataset\n",
        "dataset = df[[target_variable] + weather_variables].copy()\n",
        "\n",
        "# Lagged and rolling features\n",
        "dataset['lag1'] = dataset[target_variable].shift(1)\n",
        "dataset['lag2'] = dataset[target_variable].shift(2)\n",
        "dataset['mean_roll'] = dataset[target_variable].rolling(window=7).mean()\n",
        "dataset['std_roll'] = dataset[target_variable].rolling(window=7).std()\n",
        "\n",
        "# Fill the missing values\n",
        "data = dataset.bfill()\n",
        "\n",
        "# Scale target and weather variables separately \n",
        "scaler = MinMaxScaler()\n",
        "scaled_weather = scaler.fit_transform(data[weather_variables])\n",
        "scaler_target = MinMaxScaler()\n",
        "scaled_target = scaler_target.fit_transform(data[[target_variable]])\n",
        "\n",
        "def create_sequences(data, time_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_steps):\n",
        "        X.append(data[i:i+time_steps])  \n",
        "        y.append(data[i+time_steps, 0])  \n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Combine variables for sequence\n",
        "combine_t_w = np.hstack([scaled_weather, scaled_target])\n",
        "\n",
        "# We are predicting for 1 year meaning 24x365 = 8760 \n",
        "time_steps = 24\n",
        "\n",
        "# Create sequences\n",
        "X, y = create_sequences(combine_t_w, time_steps)\n",
        "\n",
        "# Training and testing split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "# y_test has one NaN, we can replace it with the mean value\n",
        "y_test = np.nan_to_num(y_test, nan=np.nanmean(y_test)) \n",
        "\n",
        "X_train = np.nan_to_num(X_train)\n",
        "y_train = np.nan_to_num(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id3yqWfnIoeI"
      },
      "source": [
        "# **Model Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Cml4Hdj4Ips9"
      },
      "outputs": [],
      "source": [
        "# Define LSTM model\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(LSTM(units=100, return_sequences=True))\n",
        "model.add(LSTM(units=50, return_sequences=False))\n",
        "model.add(Dense(units=25, activation='relu'))\n",
        "model.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001, clipnorm=1.0)\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae', MeanAbsolutePercentageError()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHkhN6x7Iqf_"
      },
      "source": [
        "# **Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HzjqrzpvIwbu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m3150/3150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 37ms/step - loss: 0.0038 - mae: 0.0156 - mean_absolute_percentage_error: 2987.7820 - val_loss: 1.8136e-05 - val_mae: 0.0019 - val_mean_absolute_percentage_error: 0.4353\n",
            "Epoch 2/100\n",
            "\u001b[1m3150/3150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 33ms/step - loss: 3.2808e-05 - mae: 0.0037 - mean_absolute_percentage_error: 733.4469 - val_loss: 2.0103e-05 - val_mae: 0.0030 - val_mean_absolute_percentage_error: 0.6044\n",
            "Epoch 3/100\n",
            "\u001b[1m3150/3150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 33ms/step - loss: 2.5826e-05 - mae: 0.0033 - mean_absolute_percentage_error: 416.6070 - val_loss: 1.3553e-05 - val_mae: 0.0024 - val_mean_absolute_percentage_error: 0.5122\n",
            "Epoch 4/100\n",
            "\u001b[1m3150/3150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 33ms/step - loss: 1.7411e-05 - mae: 0.0027 - mean_absolute_percentage_error: 406.3524 - val_loss: 2.0353e-05 - val_mae: 0.0038 - val_mean_absolute_percentage_error: 0.8062\n",
            "Epoch 5/100\n",
            "\u001b[1m3150/3150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 33ms/step - loss: 1.7412e-05 - mae: 0.0025 - mean_absolute_percentage_error: 400.7189 - val_loss: 5.8327e-06 - val_mae: 7.5699e-04 - val_mean_absolute_percentage_error: 0.1681\n",
            "Epoch 6/100\n",
            "\u001b[1m3150/3150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 34ms/step - loss: 1.1321e-05 - mae: 0.0018 - mean_absolute_percentage_error: 269.2142 - val_loss: 1.2882e-05 - val_mae: 0.0028 - val_mean_absolute_percentage_error: 0.5812\n",
            "Epoch 7/100\n",
            "\u001b[1m3150/3150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 35ms/step - loss: 1.2537e-05 - mae: 0.0021 - mean_absolute_percentage_error: 338.4347 - val_loss: 1.3927e-05 - val_mae: 0.0030 - val_mean_absolute_percentage_error: 0.6415\n",
            "Epoch 8/100\n",
            "\u001b[1m3150/3150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 32ms/step - loss: 1.1014e-05 - mae: 0.0019 - mean_absolute_percentage_error: 350.3560 - val_loss: 6.3923e-06 - val_mae: 0.0012 - val_mean_absolute_percentage_error: 0.2552\n",
            "Epoch 9/100\n",
            "\u001b[1m3150/3150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 35ms/step - loss: 1.0963e-05 - mae: 0.0019 - mean_absolute_percentage_error: 363.1069 - val_loss: 8.6688e-06 - val_mae: 0.0020 - val_mean_absolute_percentage_error: 0.4406\n",
            "Epoch 10/100\n",
            "\u001b[1m3150/3150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 34ms/step - loss: 1.0618e-05 - mae: 0.0018 - mean_absolute_percentage_error: 373.6404 - val_loss: 1.0464e-05 - val_mae: 0.0024 - val_mean_absolute_percentage_error: 0.5141\n",
            "Epoch 11/100\n",
            "\u001b[1m3150/3150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 33ms/step - loss: 1.0652e-05 - mae: 0.0018 - mean_absolute_percentage_error: 358.2390 - val_loss: 2.4855e-05 - val_mae: 0.0044 - val_mean_absolute_percentage_error: 0.9122\n",
            "Epoch 12/100\n",
            "\u001b[1m3150/3150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 34ms/step - loss: 1.0229e-05 - mae: 0.0017 - mean_absolute_percentage_error: 469.1311 - val_loss: 9.7066e-06 - val_mae: 0.0023 - val_mean_absolute_percentage_error: 0.4881\n"
          ]
        }
      ],
      "source": [
        "# Early stop (7 times before stopping)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "\n",
        "# Train LSTM\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=128, validation_data=(X_test, y_test), verbose=1, callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6oOgVGiIxSp"
      },
      "source": [
        "# **Evaluate the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sLmjp4-9I06s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 99.831879%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the LSTM model\n",
        "loss, mae, mape = model.evaluate(X_test, y_test, verbose=0)\n",
        "accuracy = 100 - mape\n",
        "print(f\"Test accuracy: {accuracy:2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPaNQFPVI1aL"
      },
      "source": [
        "# **Predictions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDYoZo31I9qI"
      },
      "source": [
        "# **Forecasting Future Energy Consumption**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
